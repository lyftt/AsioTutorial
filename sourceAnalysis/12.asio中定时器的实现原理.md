# asio中定时器的实现原理
asio中的定时器的实现是堆（Heap）；
asio中核心类的大致关系：
- `steady_timer`，表示一个定时器，包含定时器的超时时间、完成回调；
- `deadline_timer_service`，表示定时器服务，内部包含一个定时器队列，用来操作定时器，例如设置超时时间、设置回调函数；
- `epoll_reactor`，表示一个调度器，用来调用定时器，检查哪些定时器超时了，最小的定时器超时时间是多少，内部最终调用`epoll_wait()`函数；


## 定时器demo例子
```C++
#include "asio.hpp"
#include <iostream>

int main() {
    // 创建I/O上下文
    asio::io_context io;

    auto wg = asio::make_work_guard(io);

    // 创建一个steady_timer对象，绑定到I/O上下文
    asio::steady_timer timer(io);

    // 设置定时器在5秒后超时
    timer.expires_after(std::chrono::seconds(5));

    // 绑定回调函数，当定时器超时时执行
    timer.async_wait([&](std::error_code ec) {
        std::cout << "5秒已到，定时器触发！" << std::endl;
        });

    // 启动I/O上下文的事件循环
    io.run();

    return 0;
}
```

## 原理分析-涉及的核心类
asio中的定时器涉及的核心类：
- `asio::steady_timer`，即`basic_waitable_timer<chrono::steady_clock>`类，这表示一个定时器对象，调用其`expires_after()`函数设置超时时间，调用其`async_wait()`函数设置时间到期的回调函数；
  
- `deadline_timer_service`，这是定时器服务类，每个定时器对象内部都会持有这个定时器服务的指针，通过这个指针来获取定时器相关的功能函数，这既然是一个服务service，那么必然是通过asio中的service管理机制进行管理的，这个定时器服务类中实现了大量和定时器相关的功能函数（例如`async_wait()`、`expires_after()`等，在上面的demo中的`timeer.expires_after()`、`timer.async_wait()`函数其实最终都是调用的这个定时器父类内部的函数）；这个类最核心的2个成员，一个定时器队列、一个指向`epoll_reactor`的引用：
```C++
  // The queue of timers.
  timer_queue<Time_Traits> timer_queue_;

  // The object that schedules and executes timers. Usually a reactor.
  timer_scheduler& scheduler_;
```
并且，在`deadline_timer_service`的构造函数中，会将自己的定时器队列`timer_queue_`添加到`scheduler_`（`epoll_reactor类`）中，那么后续修改`deadline_timer_service`中的定时器队列其实就是修改`epoll_reactor`中的定时器队列，建立了关联；
```C++
  // Constructor.
  deadline_timer_service(execution_context& context)
    : execution_context_service_base<
        deadline_timer_service<Time_Traits>>(context),
      scheduler_(asio::use_service<timer_scheduler>(context))
  {
    scheduler_.init_task();
    scheduler_.add_timer_queue(timer_queue_);
  }
```
这说明`epoll_reactor`内部其实支持不只一个定时器队列，可以有多个定时器队列!

  
- `epoll_reactor`，`deadline_timer_service`这个定时器服务类中持有了一个`timer_scheduler& scheduler_`，这个`timer_scheduler`其实就是`epoll_reactor`的类型别名，这个`epoll_reactor`也是一个服务类，也是通过asio中的service管理机制进行管理的，`deadline_timer_service`这个定时器服务类的大量功能函数最终就是通过`epoll_reactor`实现的；比如`deadline_timer_service`类的`async_wait()`函数内部最终调用的就是这个`epoll_reactor`的`schedule_timer()`函数；
 

  
- `deadline_timer_service::implementation_type`，这是定时器的实现类，其内部是定时器的相关数据（超时时间、定时器的完成队列、定时器在堆中的索引）；
```C++
struct implementation_type
    : private asio::detail::noncopyable
  {
    time_type expiry;
    bool might_have_pending_waits;
    typename timer_queue<Time_Traits>::per_timer_data timer_data;
  };
```

  
- `timer_queue`，这表示一个基于堆实现的定时器队列，就是`deadline_timer_service`内部的定时器队列成员，在调用`deadline_timer_service`的`async_wait()`函数的时候就会将定时器加入到这个队列中:
```C++
  template <typename Handler, typename IoExecutor>
  void async_wait(implementation_type& impl,
      Handler& handler, const IoExecutor& io_ex)
  {
    associated_cancellation_slot_t<Handler> slot
      = asio::get_associated_cancellation_slot(handler);

    // Allocate and construct an operation to wrap the handler.
    typedef wait_handler<Handler, IoExecutor> op;
    typename op::ptr p = { asio::detail::addressof(handler),
      op::ptr::allocate(handler), 0 };
    p.p = new (p.v) op(handler, io_ex);

    // Optionally register for per-operation cancellation.
    if (slot.is_connected())
    {
      p.p->cancellation_key_ =
        &slot.template emplace<op_cancellation>(this, &impl.timer_data);
    }

    impl.might_have_pending_waits = true;

    ASIO_HANDLER_CREATION((scheduler_.context(),
          *p.p, "deadline_timer", &impl, 0, "async_wait"));

    scheduler_.schedule_timer(timer_queue_, impl.expiry, impl.timer_data, p.p);   //这里的timer_queue_就是deadline_timer_service内部的定时队列成员
    p.v = p.p = 0;
  }
```
`timer_queue`继承于`timer_queue_base`，`timer_queue_base`是一个定时器队列的抽象类（接口），定义了定时器队列应该提供的通用函数（例如获取定时器队列中就绪的定时器的完成回调函数等），`timer_queue`最核心的成员有2个，一个是本定时器队列中所有定时器的实现类指针组成的双向链表`timers_`，另一个是每个基于所有定时器的超时时间建立的堆`heap_`:
```C++
  // The head of a linked list of all active timers.
  per_timer_data* timers_;

  struct heap_entry
  {
    // The time when the timer should fire.
    time_type time_;

    // The associated timer with enqueued operations.
    per_timer_data* timer_;
  };

  // The heap of timers, with the earliest timer at the front.
  std::vector<heap_entry> heap_;
```


`io_context`，这是io事件调度器，其`run()`函数内部最终会调用`scheduler`类的`run()`函数（`io_context`内部的核心功能都是由`scheduler`实现的）；


`scheduler`，这是真正的调度类，其内部的大致逻辑：内部会不停的从完成队列`op_queue_`中取出完成回调对象`operation`，然后执行，这个`operation`有2种可能：\
**（1）真正的用户的完成回调函数；** \
**（2）调度任务，调度任务也被一起抽象为了operation，这种情况就会执行`task_`的`run()`函数进行调度（本质是`epoll_reactor::run()`），这个函数中队中就是调用`epoll_wait()`函数了；**



## 原理分析-整个执行过程

### asio::steady_timer timer(io)
这一步是创建了一个定时器对象，其实就是一个`basic_waitable_timer`类对象（`steady_timer`是类型别名），其内部的核心成员`io_object_impl`也会完成构造，其使用的定时器服务service是`deadline_timer_service`（这个service如果不存在则也会通过service管理机制进行创建）；

构造函数：
```C++
  template <typename ExecutionContext>
  explicit io_object_impl(int, int, ExecutionContext& context)
    : service_(&asio::use_service<IoObjectService>(context)),
      executor_(context.get_executor())
  {
    service_->construct(implementation_);
  }
```
上面的逻辑就是找出要使用的定时器服务`deadline_timer_service`，最后在构造函数体里构造定时器的内部核心实现类`implementation_`；


其核心成员：
```C++
detail::io_object_impl<
    detail::deadline_timer_service<
      detail::chrono_time_traits<Clock, WaitTraits>>,
    executor_type > impl_;
```
上面这个`impl_`内部就包含了这个定时器的具体实现信息：
```C++
  // The service associated with the I/O object.
  service_type* service_;

  // The underlying implementation of the I/O object.
  implementation_type implementation_;

  // The associated executor.
  executor_type executor_;
```
上面的`service_`是这个定时器使用的定时器服务service，也就是`deadline_timer_service`类对象，`implementation_`则是本定时器的核心实现数据（超时时间、定时器的完成队列、定时器在堆中的索引）


还需要关注下如果`deadline_timer_service`不存在，那么asio的service管理机制就会创建这个service，`deadline_timer_service`在构造的时候，会做下面的操作：
```C++
  // Constructor.
  deadline_timer_service(execution_context& context)
    : execution_context_service_base<
        deadline_timer_service<Time_Traits>>(context),
      scheduler_(asio::use_service<timer_scheduler>(context))
  {
    scheduler_.init_task();
    scheduler_.add_timer_queue(timer_queue_);
  }
```
上面的`deadline_timer_service`构造函数会调用`scheduler_`（就是`epoll_reactor`）的初始化函数，将`deadline_timer_service`的定时器队列关联到`scheduler_`中，后面`epoll_reactor`调度的时候就会直接访问这个`deadline_timer_service`的定时器队列；


这一步之后，定时器对象被创建出来（其内部的核心实现类型对象也被创建出来），要使用的定时器服务service也被创建出来，下面就要对这个定时器进行配置了；


### timer.expires_after(std::chrono::seconds(5))
这个函数就是在对创建出来的定时器进行配置，其代码：
```C++
std::size_t expires_after(const duration& expiry_time)
  {
    asio::error_code ec;
    std::size_t s = impl_.get_service().expires_after(
        impl_.get_implementation(), expiry_time, ec);
    asio::detail::throw_error(ec, "expires_after");
    return s;
  }
```
可以看到上面代码中最终就是调用了`deadline_timer_service`这个service中的`expires_after()`函数，其第一个参数就是定时器对象内部实现对象，第二个参数就是用户传入的超时时间；

继续看下面`expires_after()`函数的代码：
```C++
// Set the expiry time for the timer as an absolute time.
  std::size_t expires_at(implementation_type& impl,
      const time_type& expiry_time, asio::error_code& ec)
  {
    std::size_t count = cancel(impl, ec);
    impl.expiry = expiry_time;
    ec = asio::error_code();
    return count;
  }

  // Set the expiry time for the timer relative to now.
  std::size_t expires_after(implementation_type& impl,
      const duration_type& expiry_time, asio::error_code& ec)
  {
    return expires_at(impl,
        Time_Traits::add(Time_Traits::now(), expiry_time), ec);
  }
```
比较简单，其实内容很简单，就是将用户传入的超时时间赋值给定时器对象的内部实现对象的`expiry`成员；


### timer.async_wait(...)
这个函数比较复杂，使用了大量的模板元编程技巧，但是最终调用的还是`deadline_timer_service`的`async_wait()`函数，这个函数的逻辑就比较直观了：
```C++
// Start an asynchronous wait on the timer.
  template <typename Handler, typename IoExecutor>
  void async_wait(implementation_type& impl,
      Handler& handler, const IoExecutor& io_ex)
  {
    associated_cancellation_slot_t<Handler> slot
      = asio::get_associated_cancellation_slot(handler);

    // Allocate and construct an operation to wrap the handler.
    typedef wait_handler<Handler, IoExecutor> op;
    typename op::ptr p = { asio::detail::addressof(handler),
      op::ptr::allocate(handler), 0 };
    p.p = new (p.v) op(handler, io_ex);

    // Optionally register for per-operation cancellation.
    if (slot.is_connected())
    {
      p.p->cancellation_key_ =
        &slot.template emplace<op_cancellation>(this, &impl.timer_data);
    }

    impl.might_have_pending_waits = true;

    ASIO_HANDLER_CREATION((scheduler_.context(),
          *p.p, "deadline_timer", &impl, 0, "async_wait"));

    scheduler_.schedule_timer(timer_queue_, impl.expiry, impl.timer_data, p.p);   //通过调度器来调度这个定时器
    p.v = p.p = 0;
  }
```
上面这个函数最终就是通过`epoll_reactor`的`schedule_timer()`函数来调度这个定时器，其第一个函数参数`timer_queue_`就是当前这个`deadline_timer_service`的定时器队列，第二个参数是要调度的定时器的超时时间，第三个参数是要调度的定时器的核心实现数据（完成回调、堆中的索引），第四个参数就是用户的完成回调；


`schedule_timer()`函数实现：
```C++
template <typename Time_Traits>
void epoll_reactor::schedule_timer(timer_queue<Time_Traits>& queue,
    const typename Time_Traits::time_type& time,
    typename timer_queue<Time_Traits>::per_timer_data& timer, wait_op* op)
{
  mutex::scoped_lock lock(mutex_);

  if (shutdown_)
  {
    scheduler_.post_immediate_completion(op, false);
    return;
  }

  bool earliest = queue.enqueue_timer(time, timer, op);
  scheduler_.work_started();
  if (earliest)
    update_timeout();
}
```
最终就是调用`deadline_timer_service`的定时器队列的`enqueue_timer()`函数，将该要调度的定时器添加到这个定时器队列中，注意，这个定时器队列其实早就和`epoll_reactor`关联起来，已经添加到其中了；返回值`earliest`表示是否需要打断调度器重新设置到期时间（就是打断`epoll_wait()函数`）；

这个`enqueue_timer()`函数将定时器添加到定时器队列中的过程：
```C++
// Add a new timer to the queue. Returns true if this is the timer that is
  // earliest in the queue, in which case the reactor's event demultiplexing
  // function call may need to be interrupted and restarted.
  bool enqueue_timer(const time_type& time, per_timer_data& timer, wait_op* op)
  {
    // Enqueue the timer object.
    if (timer.prev_ == 0 && &timer != timers_)
    {
      if (this->is_positive_infinity(time))
      {
        // No heap entry is required for timers that never expire.
        timer.heap_index_ = (std::numeric_limits<std::size_t>::max)();
      }
      else
      {
        // Put the new timer at the correct position in the heap. This is done
        // first since push_back() can throw due to allocation failure.
        timer.heap_index_ = heap_.size();
        heap_entry entry = { time, &timer };
        heap_.push_back(entry);
        up_heap(heap_.size() - 1);
      }

      // Insert the new timer into the linked list of active timers.
      timer.next_ = timers_;
      timer.prev_ = 0;
      if (timers_)
        timers_->prev_ = &timer;
      timers_ = &timer;
    }

    // Enqueue the individual timer operation.
    timer.op_queue_.push(op);

    // Interrupt reactor only if newly added timer is first to expire.
    return timer.heap_index_ == 0 && timer.op_queue_.front() == op;
  }
```
上面的过程做了3件事：\
（1）将要调度的定时器添加到定时器队列的堆`heap_`中；
（2）将要调度的定时器添加到定时器队列的定时器双向链表`timers_`中；
（3）判断这个新添加的定时器是不是在堆顶部，如果是的话就需要打断`epoll_wait()`函数，重新定时，因为之前的定时时间已经不是最小的了；

到这，已经将要调度的定时器放到了调度器会调度的定时器队列中，调度器已经能够找到它并进行调度了，接下来就是需要启动调度器；


### io.run()
这个函数就是最终启动调度器，`io_context`的`run()`函数最终调用的是其内部实现类型`scheduler`的`run()`函数，其核心逻辑就是从完成队列中取出完成回调并执行或者执行调度任务；
```C++
std::size_t scheduler::run(asio::error_code& ec)
{
  ec = asio::error_code();
  if (outstanding_work_ == 0)   //检查待处理的工作
  {
    stop();   //没有要处理的工作就停止
    return 0;
  }

  thread_info this_thread;    //初始化当前线程的状态信息
  this_thread.private_outstanding_work = 0;  //初始化当前线程的私有化工作数量
  thread_call_stack::context ctx(this, this_thread);  //创建当前线程的调用栈上下文，将调度器和当前线程关联起来

  mutex::scoped_lock lock(mutex_);    //加锁保护，可以多个线程同时调用io_context.run()

  std::size_t n = 0;
  for (; do_run_one(lock, this_thread, ec); lock.lock())  //do_run_one()函数内部会解锁
    if (n != (std::numeric_limits<std::size_t>::max)())
      ++n;
  return n;
}
```
这个`run()`函数内部会为执行这个`run()`函数的线程创建一个当前线程的信息对象`thread_info`，因为可能同时多个线程执行同一个`io_context`的`run()`函数，每个线程有自己的完成回调队列就可以避免竞争的开销：
```C++
struct scheduler_thread_info : public thread_info_base
{
  op_queue<scheduler_operation> private_op_queue;   //线程私有的完成回调队列，区别于调度器的完成回调队列
  long private_outstanding_work;                    //线程私有的待处理的工作
};
```

下面看下`do_run_one()`函数：
```C++
std::size_t scheduler::do_run_one(mutex::scoped_lock& lock,
    scheduler::thread_info& this_thread,
    const asio::error_code& ec)
{
  while (!stopped_)
  {
    if (!op_queue_.empty())   //这里是调度器的完成回调队列
    {
      // Prepare to execute first handler from queue.
      operation* o = op_queue_.front();   //从完成回调队列取出operation
      op_queue_.pop();
      bool more_handlers = (!op_queue_.empty());

      if (o == &task_operation_)   //判断operation是调度任务，而不是用户的完成回调函数
      {
        task_interrupted_ = more_handlers;

        if (more_handlers && !one_thread_)   //还有更多operation且开启多线程优化则解锁并唤醒另一个线程继续处理
          wakeup_event_.unlock_and_signal_one(lock);
        else
          lock.unlock();

        task_cleanup on_exit = { this, &lock, &this_thread };   //这里on_exit的析构函数里会再次向调度器的完成队列中push一个task_operation_，表示下次还要继续调度
        (void)on_exit;   //消除编译器警告

        // Run the task. May throw an exception. Only block if the operation
        // queue is empty and we're not polling, otherwise we want to return
        // as soon as possible.
        task_->run(more_handlers ? 0 : -1, this_thread.private_op_queue);   //这里就是执行epoll_reactor::run()，最终就是调用到epoll_wait()函数，将就绪的完成回调放入线程私有的完成队列中
      }
      else  //判断是用户的完成回调函数
      {
        std::size_t task_result = o->task_result_;

        if (more_handlers && !one_thread_)   //还有更多operation且开启多线程优化则解锁并唤醒另一个线程继续处理
          wake_one_thread_and_unlock(lock);
        else
          lock.unlock();

        // Ensure the count of outstanding work is decremented on block exit.
        work_cleanup on_exit = { this, &lock, &this_thread };
        (void)on_exit;

        // Complete the operation. May throw an exception. Deletes the object.
        o->complete(this, ec, task_result);    //执行用户的完成回调函数
        this_thread.rethrow_pending_exception();

        return 1;    //处理完一个用户的完成回调函数就会直接返回
      }
    }
    else   //完成队列空的则进行等待
    {
      wakeup_event_.clear(lock);
      wakeup_event_.wait(lock);
    }
  }

  return 0;
}
```
上面的`do_run_one()`函数会判断调度器的完成回调队列`op_queue_`是否为空，为空则直接进行等待（这里的`wakeup_event_`其实就是包装的条件变量），如果不空则会从中取出一个operation执行，执行前会判断这个operation是不是调度任务，如果是调度任务则执行调度任务的`run()`函数（最终通过`epoll_wait()`进行调度）；如果是用户的完成回调函数则直接执行完后直接结束函数（`do_run_one()`一次最多只会执行一个用户完成回调函数）；


在上面的`do_run_one()`函数中，锁的主要作用就是保护完成队列`op_queue_`并配合`wakeup_event_`实现同步，`do_run_one()`函数每次只会从完成队列中取出最多一个operation就会解锁然后去处理这个operation，这样如果有其他线程也在运行`io_context.run()`的话，就会及时通知其他线程去完成回调队列中去operation进行处理，所以锁的范围其实很小；


回到定时器的功能上，`timer.async_wait(...)`函数最终将要调度的定时器放到了调度器会调度的定时器队列中，`io.run()`则是启动调度器，最终通过`task_->run(more_handlers ? 0 : -1, this_thread.private_op_queue);`开始调度，看下其内部的核心代码：
```C++
void epoll_reactor::run(long usec, op_queue<operation>& ops)
{
  // This code relies on the fact that the scheduler queues the reactor task
  // behind all descriptor operations generated by this function. This means,
  // that by the time we reach this point, any previously returned descriptor
  // operations have already been dequeued. Therefore it is now safe for us to
  // reuse and return them for the scheduler to queue again.

  // Calculate timeout. Check the timer queues only if timerfd is not in use.
  int timeout;
  if (usec == 0)
    timeout = 0;
  else
  {
    timeout = (usec < 0) ? -1 : ((usec - 1) / 1000 + 1);
    if (timer_fd_ == -1)
    {
      mutex::scoped_lock lock(mutex_);
      timeout = get_timeout(timeout);
    }
  }

  // Block on the epoll descriptor.
  epoll_event events[128];
  int num_events = epoll_wait(epoll_fd_, events, 128, timeout);   //终于调用到epoll_wait

......

#if defined(ASIO_HAS_TIMERFD)
  bool check_timers = (timer_fd_ == -1);
#else // defined(ASIO_HAS_TIMERFD)
  bool check_timers = true;
#endif // defined(ASIO_HAS_TIMERFD)

  // Dispatch the waiting events.
  for (int i = 0; i < num_events; ++i)   //调度就绪的事件
  {
    void* ptr = events[i].data.ptr;
    if (ptr == &interrupter_)     //表示被打断
    {
      // No need to reset the interrupter since we're leaving the descriptor
      // in a ready-to-read state and relying on edge-triggered notifications
      // to make it so that we only get woken up when the descriptor's epoll
      // registration is updated.

#if defined(ASIO_HAS_TIMERFD)
      if (timer_fd_ == -1)
        check_timers = true;
#else // defined(ASIO_HAS_TIMERFD)
      check_timers = true;
#endif // defined(ASIO_HAS_TIMERFD)
    }
#if defined(ASIO_HAS_TIMERFD)
    else if (ptr == &timer_fd_)   //是定时器就绪了
    {
      check_timers = true;
    }
#endif // defined(ASIO_HAS_TIMERFD)
    else    //是io事件就绪了
    {
      // The descriptor operation doesn't count as work in and of itself, so we
      // don't call work_started() here. This still allows the scheduler to
      // stop if the only remaining operations are descriptor operations.
      descriptor_state* descriptor_data = static_cast<descriptor_state*>(ptr);
      if (!ops.is_enqueued(descriptor_data))
      {
        descriptor_data->set_ready_events(events[i].events);
        ops.push(descriptor_data);
      }
      else
      {
        descriptor_data->add_ready_events(events[i].events);
      }
    }
  }

  if (check_timers)  //需要处理定时器
  {
    mutex::scoped_lock common_lock(mutex_);
    timer_queues_.get_ready_timers(ops);   //获取所有到期的定时器的完成回调函数，放入ops中，这个ops是每个线程独立的完成回调队列

#if defined(ASIO_HAS_TIMERFD)
    if (timer_fd_ != -1)
    {
      itimerspec new_timeout;
      itimerspec old_timeout;
      int flags = get_timeout(new_timeout);   //获取下一个最近的定时器的超时时间
      timerfd_settime(timer_fd_, flags, &new_timeout, &old_timeout);  //重新设置超时时间
    }
#endif // defined(ASIO_HAS_TIMERFD)
  }
}
```
上面的代码其实就是比较常见的通过`epoll_wait()`和`timerfd`机制实现定时器功能的代码了；需要注意的是，`epoll_wait()`返回后会将就绪的定时器的完成回调函数通过`ops`返回，这是是之前给每个线程创建的独立的完成回调队列，这个队列又是通过`on_exit`放入了调度器的完成回调队列中：
```C++
if (o == &task_operation_)
{
task_interrupted_ = more_handlers;

if (more_handlers && !one_thread_)
    wakeup_event_.unlock_and_signal_one(lock);
else
    lock.unlock();

task_cleanup on_exit = { this, &lock, &this_thread };     //这里的on_exit的析构函数非常重要
(void)on_exit;

// Run the task. May throw an exception. Only block if the operation
// queue is empty and we're not polling, otherwise we want to return
// as soon as possible.
task_->run(more_handlers ? 0 : -1, this_thread.private_op_queue);
}


struct scheduler::task_cleanup
{
  ~task_cleanup()   //这个析构函数实现了线程私有完成回调队列合并到调度器完成回调队列的操作
  {
    if (this_thread_->private_outstanding_work > 0)
    {
      asio::detail::increment(
          scheduler_->outstanding_work_,
          this_thread_->private_outstanding_work);
    }
    this_thread_->private_outstanding_work = 0;

    // Enqueue the completed operations and reinsert the task at the end of
    // the operation queue.
    lock_->lock();
    scheduler_->task_interrupted_ = true;
    scheduler_->op_queue_.push(this_thread_->private_op_queue);    //将线程私有完成回调队列合并到调度器完成回调队列
    scheduler_->op_queue_.push(&scheduler_->task_operation_);      //再次进行调度
  }

  scheduler* scheduler_;
  mutex::scoped_lock* lock_;
  thread_info* this_thread_;
};
```


